{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if operation == add\n",
    "\n",
    "string = \"can you add an experience to my profile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experience\n"
     ]
    }
   ],
   "source": [
    "sections = ['experience', 'education', 'project']\n",
    "for w in word_tokenize(string):\n",
    "    if(w in sections):\n",
    "        for sec in sections:\n",
    "            if(w == sec):\n",
    "                print(w)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding synonyms of the word search...\n",
      "Stemming...\n",
      "Lemmitizating...\n",
      "Resultant list: \n",
      "['find a lost item', 'find', 'find inform', 'rout up', 'explor', 'forag', 'frisk', 'hunt', 'look', 'manhunt', 'pursuit', 'quest', 'ransack', 'scour', 'search']\n",
      "\n",
      "\n",
      "Finding synonyms of the word add...\n",
      "Stemming...\n",
      "Lemmitizating...\n",
      "Resultant list: \n",
      "['add', 'comput a sum', 'add on', 'adjoin', 'button', 'butyl', 'compound', 'concaten', 'enrich', 'foot', 'fortifi', 'gild the lili', 'includ', 'inject', 'intercal']\n",
      "\n",
      "\n",
      "Tranformed string is: ['Can', 'search', 'himanshu', 'singh']\n",
      "Operation: search\n"
     ]
    }
   ],
   "source": [
    "import LinkedIn_Operation_identification\n",
    "\n",
    "# dir(LinkedIn_Operation_identification_Copy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding synonyms of the word search...\n",
      "Stemming...\n",
      "Lemmitizating...\n",
      "Resultant list: \n",
      "['find a lost item', 'find', 'find inform', 'rout up', 'explor', 'forag', 'frisk', 'hunt', 'look', 'manhunt', 'pursuit', 'quest', 'ransack', 'scour', 'search']\n",
      "\n",
      "\n",
      "Finding synonyms of the word add...\n",
      "Stemming...\n",
      "Lemmitizating...\n",
      "Resultant list: \n",
      "['add', 'comput a sum', 'add on', 'adjoin', 'button', 'butyl', 'compound', 'concaten', 'enrich', 'foot', 'fortifi', 'gild the lili', 'includ', 'inject', 'intercal']\n",
      "\n",
      "\n",
      "Tranformed string is: ['Can', 'search', 'himanshu', 'singh']\n",
      "Operation: search\n"
     ]
    }
   ],
   "source": [
    "from LinkedIn_Operation_identification import findSynonyms, lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function findSynonyms in module LinkedIn_Operation_identification:\n",
      "\n",
      "findSynonyms(word1, level='start')\n",
      "    returns a list of the synynoms of the word by considering the level(start or end)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(findSynonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1dbf29b21576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msectionsSyn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msectionsSyn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "synSections = []\n",
    "for sec in sections:\n",
    "    synSections.append(findSynonyms(sec))\n",
    "    \n",
    "sectionsSyn = []\n",
    "for idx, sec in enumerate(synSections):\n",
    "    for i, cur in enumerate(sec):\n",
    "        if( i == 0):\n",
    "            sectionsSyn[i, idx] = cur\n",
    "            continue\n",
    "        if cur not in sectionsSyn:\n",
    "            sectionsSyn.append(cur)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['subject',\n",
       "  'a person',\n",
       "  'experience',\n",
       "  'appalling',\n",
       "  'augury',\n",
       "  'experience',\n",
       "  'experience',\n",
       "  'experience',\n",
       "  'familiarization',\n",
       "  'flash',\n",
       "  'good time',\n",
       "  'life',\n",
       "  'loss',\n",
       "  'near-death experience',\n",
       "  'ordeal',\n",
       "  'out-of-body experience',\n",
       "  'reliving',\n",
       "  'reminder',\n",
       "  'taste',\n",
       "  'time'],\n",
       " ['school',\n",
       "  'education',\n",
       "  'going to school',\n",
       "  'seeing art',\n",
       "  'Education',\n",
       "  'Educação',\n",
       "  'watching television',\n",
       "  'a classroom',\n",
       "  'reading',\n",
       "  'college',\n",
       "  'education',\n",
       "  'education',\n",
       "  'education',\n",
       "  'attending school',\n",
       "  'educationist',\n",
       "  'academic program',\n",
       "  'Department of Education',\n",
       "  'education',\n",
       "  'point system',\n",
       "  'tuition'],\n",
       " ['A project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'moneymaker',\n",
       "  'A project',\n",
       "  'project',\n",
       "  'introduce',\n",
       "  'offer',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'project',\n",
       "  'shoot',\n",
       "  'silhouette',\n",
       "  'projection']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synSections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 'u',\n",
       " 'b',\n",
       " 'j',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'a person',\n",
       " 'experience',\n",
       " 'appalling',\n",
       " 'augury',\n",
       " 'familiarization',\n",
       " 'flash',\n",
       " 'good time',\n",
       " 'life',\n",
       " 'loss',\n",
       " 'near-death experience',\n",
       " 'ordeal',\n",
       " 'out-of-body experience',\n",
       " 'reliving',\n",
       " 'reminder',\n",
       " 'taste',\n",
       " 'time',\n",
       " 's',\n",
       " 'c',\n",
       " 'h',\n",
       " 'o',\n",
       " 'o',\n",
       " 'l',\n",
       " 'education',\n",
       " 'going to school',\n",
       " 'seeing art',\n",
       " 'Education',\n",
       " 'Educação',\n",
       " 'watching television',\n",
       " 'a classroom',\n",
       " 'reading',\n",
       " 'college',\n",
       " 'attending school',\n",
       " 'educationist',\n",
       " 'academic program',\n",
       " 'Department of Education',\n",
       " 'point system',\n",
       " 'tuition',\n",
       " 'A',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'j',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'project',\n",
       " 'moneymaker',\n",
       " 'A project',\n",
       " 'introduce',\n",
       " 'offer',\n",
       " 'shoot',\n",
       " 'silhouette',\n",
       " 'projection']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectionsSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synSections = np.array(synSections)\n",
    "synSections = np.transpose(synSections)\n",
    "synSections.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>education</th>\n",
       "      <th>project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject</td>\n",
       "      <td>school</td>\n",
       "      <td>A project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a person</td>\n",
       "      <td>education</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experience</td>\n",
       "      <td>going to school</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appalling</td>\n",
       "      <td>seeing art</td>\n",
       "      <td>moneymaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augury</td>\n",
       "      <td>Education</td>\n",
       "      <td>A project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experience        education     project\n",
       "0     subject           school   A project\n",
       "1    a person        education     project\n",
       "2  experience  going to school     project\n",
       "3   appalling       seeing art  moneymaker\n",
       "4      augury        Education   A project"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synProfileSec = pd.DataFrame(synSections, columns=sections)\n",
    "synProfileSec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synProfileSec.to_csv('synProfileSec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmitizating...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4af80148a401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#remove stop_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnoSW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstpword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mlemmaSynWord\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "synSection = []\n",
    "for sec in synSections:\n",
    "#     StemmedSynWord = stemming(sec)\n",
    "\n",
    "    print(\"Lemmitizating...\")\n",
    "    lemmaSynWord = lemmitization(sec)\n",
    "    \n",
    "    #remove stop_words\n",
    "    noSW = []\n",
    "    stpword = set(stopwords.words(\"english\"))\n",
    "    for word  in lemmaSynWord:\n",
    "        print(word)\n",
    "        if(len(word_tokenize(word)) > 1):\n",
    "            temp = \"\".join([w for w in word_tokenize(word) if w not in stpword])\n",
    "            noSW.append(temp)\n",
    "        else:\n",
    "            noSW.append(word)\n",
    "            \n",
    "    print(\"Resultant list: \")\n",
    "    print(noSW)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    synSection.append(noSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synSections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load LinkedIn_Operation_identification_Copy1\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def Transform(inputString, lower = False):\n",
    "    \"\"\"\n",
    "    Removes puctuation marks, lowers and splits the string into words and removes stop words from the list\n",
    "    \"\"\"\n",
    "    # remove punctuation marks from string\n",
    "    string = re.sub(\"[^a-zA-Z0-9]\", \" \", inputString)\n",
    "    \n",
    "    if(lower):\n",
    "        string = string.lower()\n",
    "    \n",
    "    #split the string\n",
    "    words = string.split()\n",
    "    \n",
    "    #remove stop words\n",
    "    stopwrds = set(stopwords.words(\"english\"))\n",
    "    noSW = [w for w in words if w not in stopwrds]\n",
    "    \n",
    "    return noSW\n",
    "\n",
    "import requests\n",
    "\n",
    "def findSynonyms(word1, level = 'start'):\n",
    "    \"\"\"\n",
    "    returns a list of the synynoms of the word by considering the level(start or end)\n",
    "    \"\"\"\n",
    "    tofind = \"http://api.conceptnet.io/c/en/\" + word1\n",
    "    obj = requests.get(tofind).json()\n",
    "    \n",
    "    #copy all the snynonyms in a list\n",
    "    synWord = []\n",
    "    \n",
    "    for i in range(len(obj['edges'])):\n",
    "        synWord.append(obj['edges'][i][level]['label'])\n",
    "\n",
    "    return synWord\n",
    "\n",
    "# stemming and lemitization\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stemming(synWord):\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    # Stemming\n",
    "    StemmedSynWord = []\n",
    "    for idx, w in enumerate(synWord):\n",
    "        w = word_tokenize(w)\n",
    "        tempword = \"\"\n",
    "        for index, every in enumerate(w):\n",
    "            tempword = tempword + (ps.stem(every))\n",
    "            if (index != len(w) - 1):\n",
    "                tempword = tempword + \" \"\n",
    "        if(tempword not in StemmedSynWord):\n",
    "            StemmedSynWord.append(tempword)\n",
    "\n",
    "    return StemmedSynWord\n",
    "\n",
    "def lemmitization(StemmedSynWord):\n",
    "    wl = WordNetLemmatizer()\n",
    "    \n",
    "    # lemmatization\n",
    "    lemmaSynWord = []\n",
    "    for idx, w in enumerate(StemmedSynWord):\n",
    "        w = word_tokenize(w)\n",
    "        tempword = \"\"\n",
    "        for index, every in enumerate(w):\n",
    "            tempword = tempword + (wl.lemmatize(every))\n",
    "            if (index != len(w) - 1):\n",
    "                tempword = tempword + \" \"\n",
    "        if(tempword not in lemmaSynWord):\n",
    "            lemmaSynWord.append(tempword)\n",
    "\n",
    "    return lemmaSynWord\n",
    "\n",
    "# words whose synonyms are to be found\n",
    "word1 = \"search\"\n",
    "word2 = \"add\"\n",
    "\n",
    "wordList = [word1, word2]\n",
    "\n",
    "synWord = []\n",
    "for word in wordList:\n",
    "    print(\"Finding synonyms of the word \" + word + \"...\")\n",
    "    synword = findSynonyms(word)\n",
    "\n",
    "    print(\"Stemming...\")\n",
    "    StemmedSynWord = stemming(synword)\n",
    "\n",
    "    print(\"Lemmitizating...\")\n",
    "    lemmaSynWord = lemmitization(StemmedSynWord)\n",
    "\n",
    "    print(\"Resultant list: \")\n",
    "    print(lemmaSynWord)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    synWord.append(lemmaSynWord)\n",
    "\n",
    "string1 = \"look for bindu singh\"\n",
    "string2 = \"Can you search for himanshu singh\"\n",
    "string3 = \"LinkedIn, add an experience in my profile\"\n",
    "string4 = \"find Himans\"\n",
    "string5 = \"What even himan?\"\n",
    "# string6 = \"I want to see Himan's profile\"\n",
    "string7 = \"Look for job openings at LinkedIn\"\n",
    "stringr2 = \"are there any senior software developer positions at linkedin\"\n",
    "\n",
    "# for number in range(1, 6):\n",
    "words = Transform(string2)\n",
    "\n",
    "print(\"Tranformed string is: \" + str(words))\n",
    "\n",
    "flag = 0\n",
    "for word in words:\n",
    "    for idx, synonyms in enumerate(synWord): \n",
    "        if(word in synonyms):        \n",
    "            print(\"Operation: \" + wordList[idx])\n",
    "            flag = 1\n",
    "            break\n",
    "        \n",
    "    if(flag == 1):\n",
    "        break\n",
    "\n",
    "if(flag == 0):\n",
    "    print(\"You are not speaking a valid operation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = 0\n",
    "for w in word_tokenize(string):\n",
    "    for idx, sec in enumerate(synSections):\n",
    "        print(sec)\n",
    "        if(w == sec):\n",
    "            flag = 1\n",
    "            print(sections[idx])\n",
    "            break\n",
    "    if(flag == 1):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
